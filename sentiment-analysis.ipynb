{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bittensorflowenvconda7abfa4292e63449e86f2f09e04d909cd",
   "display_name": "Python 3.7.6 64-bit ('tensorflow_env': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "from io import StringIO, BytesIO\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rankings_and_train():\n",
    "    result = {}\n",
    "    try:\n",
    "        s3 = boto3.client('s3', aws_access_key_id='AKIAVQKNDIV2NXOW4UYX', aws_secret_access_key='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')\n",
    "\n",
    "        filepath_dict = {'yelp': 'sentiment-analysis/yelp_labelled.txt',\n",
    "                 'amazon': 'sentiment-analysis/amazon_cells_labelled.txt',\n",
    "                 'imdb': 'sentiment-analysis/imdb_labelled.txt'}\n",
    "\n",
    "        df_list = []\n",
    "        for source, filepath in filepath_dict.items():\n",
    "            obj = s3.get_object(Bucket='ml-data.s3.us-east-1.amazonaws.com', Key=filepath)\n",
    "            df = pd.read_csv(BytesIO(obj['Body'].read()), names=['sentence', 'label'], sep='\\t')\n",
    "            df['source'] = source  # Add another column filled with the source name\n",
    "            df_list.append(df)\n",
    "            df = pd.concat(df_list)\n",
    "        \n",
    "        \n",
    "        total_score = 0\n",
    "\n",
    "        for source in df['source'].unique():\n",
    "            df_source = df[df['source'] == source]\n",
    "            sentences = df_source['sentence'].values\n",
    "            y = df_source['label'].values\n",
    "\n",
    "            sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "                sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "            vectorizer.fit(sentences_train)\n",
    "            X_train = vectorizer.transform(sentences_train)\n",
    "            X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "            \n",
    "            classifier.fit(X_train, y_train)\n",
    "            score = classifier.score(X_test, y_test)\n",
    "            print('Accuracy for {} data: {:.4f}'.format(source, score))\n",
    "            total_score += score\n",
    "\n",
    "        \n",
    "        if(total_score):\n",
    "            total_score /= 3\n",
    "\n",
    "        result = {\n",
    "            'training_avg_score': total_score\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    review_transformed = vectorizer.transform(sentence)\n",
    "    review_result = classifier.predict(review_transformed)\n",
    "    print(review_result[0])\n",
    "    review = 'Positive review' if review_result[0] == 1 else 'Negative Review'\n",
    "    print(review)\n",
    "    result = {\n",
    "        \"review\": review\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy for yelp data: 0.7960\nAccuracy for amazon data: 0.7960\nAccuracy for imdb data: 0.7487\n1\nPositive review\n{'review': 'Positive review'}\n"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "result = read_rankings_and_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0\nNegative Review\n{'review': 'Negative Review'}\n"
    }
   ],
   "source": [
    "result = predict(['I hate this'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    s3 = boto3.client('s3', aws_access_key_id='AKIAVQKNDIV2NXOW4UYX', aws_secret_access_key='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')\n",
    "    buckets = s3.list_buckets()\n",
    "\n",
    "    # Output the bucket names\n",
    "    print('Existing buckets:')\n",
    "    for bucket in buckets['Buckets']:\n",
    "        print(f'  {bucket[\"Name\"]}')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = s3.list_objects_v2(Bucket='ml-data.s3.us-east-1.amazonaws.com')\n",
    "for item in response['Contents']:\n",
    "    print(item['Key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'yelp': 'sentiment-analysis/yelp_labelled.txt',\n",
    "                 'amazon': 'sentiment-analysis/amazon_cells_labelled.txt',\n",
    "                 'imdb': 'sentiment-analysis/imdb_labelled.txt'}\n",
    "\n",
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    obj = s3.get_object(Bucket='ml-data.s3.us-east-1.amazonaws.com', Key=filepath)\n",
    "    df = pd.read_csv(BytesIO(obj['Body'].read()), names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source  # Add another column filled with the source name\n",
    "    df_list.append(df)\n",
    "    df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.get_object(Bucket='ml-data.s3.us-east-1.amazonaws.com', Key='amazon_cells_labelled.txt')\n",
    "try:\n",
    "    df = pd.read_csv(BytesIO(obj['Body'].read()))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_my_buckets(s3):\n",
    "    print('Buckets:\\n\\t', *[b.name for b in s3.buckets.all()], sep=\"\\n\\t\")\n",
    "\n",
    "\n",
    "# def handler_name(event, context):\n",
    "#     if event['EventType'] = 'helper1':\n",
    "#         result = start_training()\n",
    "#     elif event['EventType'] = 'helper2':\n",
    "#         result = predict(event, context)\n",
    "\n",
    "#     return {\n",
    "#         'statusCode': 200,\n",
    "#         'body': json.dumps(result)\n",
    "#     }\n",
    "\n",
    "\n",
    "def start_training():\n",
    "    conn = boto.connect_s3(\n",
    "            aws_access_key_id = access_key,\n",
    "            aws_secret_access_key = secret_key,\n",
    "            host = 'objects.dreamhost.com',\n",
    "            calling_format = boto.s3.connection.OrdinaryCallingFormat(),\n",
    "        )\n",
    "    filepath_dict = {'yelp': 'data/yelp_labelled.txt',\n",
    "                 'amazon': 'data/amazon_cells_labelled.txt',\n",
    "                 'imdb': 'data/imdb_labelled.txt'}\n",
    "\n",
    "    df_list = []\n",
    "    for source, filepath in filepath_dict.items():\n",
    "        df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "        df['source'] = source  # Add another column filled with the source name\n",
    "        df_list.append(df)\n",
    "        df = pd.concat(df_list)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    total_score = 0\n",
    "\n",
    "    for source in df['source'].unique():\n",
    "        df_source = df[df['source'] == source]\n",
    "        sentences = df_source['sentence'].values\n",
    "        y = df_source['label'].values\n",
    "\n",
    "        sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "            sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "        vectorizer.fit(sentences_train)\n",
    "        X_train = vectorizer.transform(sentences_train)\n",
    "        X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "        classifier = LogisticRegression()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        score = classifier.score(X_test, y_test)\n",
    "        print('Accuracy for {} data: {:.4f}'.format(source, score))\n",
    "\n",
    "    \n",
    "    if(total_score):\n",
    "        total_score /= 3\n",
    "\n",
    "    result = {\n",
    "        \"training_avg_score\": total_score\n",
    "    }\n",
    "    return result\n",
    "\n",
    "\n",
    "def predict(event, context):\n",
    "    positive_review = ['I love this']\n",
    "    review_transformed = vectorizer.transform(positive_review)\n",
    "    review_result = classifier.predict(review_transformed)\n",
    "    print(review_result[0])\n",
    "    review = 'Positive review' if review_result[0] == 1 else 'Negative Review'\n",
    "    print(review)\n",
    "    result = {\n",
    "        \"review\": review\n",
    "    }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}